{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8l2Kg-mZ1Pb"
      },
      "source": [
        "# Image segmentation code for Detectron2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Install Detectron2\n",
        "\n",
        "First step is to install detectron2.\n",
        "Full installation documentation here - https://detectron2.readthedocs.io/en/latest/tutorials/install.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "\n",
        "# # On macOS, you may need to prepend the above commands with a few environment variables:\n",
        "# CC=clang CXX=clang++ ARCHFLAGS=\"-arch x86_64\" python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTO_K23JaAxg"
      },
      "source": [
        "# 2. Create annotations for your image files\n",
        "\n",
        "For detectron2 to work, you will need to annotate your images. We have done this using https://www.makesense.ai/ to create object detection annotations in COCO JSON format.\n",
        "\n",
        "You should generate one json file for each set. There should be a training set josn file, and an internal validation set json file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Set your directories to the training and internal validation images and accompanying json annotation files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# First set your training set\n",
        "# Folder to training images\n",
        "training_set_images = \"path_to_training_images\"\n",
        "training_set_annotations = \"path_to_training_json_file\"\n",
        "\n",
        "# Second set your internal validation set\n",
        "# Folder to internal validation images\n",
        "validation_set_images = \"path_to_validation_images\"\n",
        "validation_set_annotations = \"path_to_validation_json_file\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ymh1ZusxDdST",
        "outputId": "f1d9195f-3ab3-4320-c317-437847a2ac9a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Specify graphic device if you have one, cpu works for all devices but is much slower\n",
        "mps_device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2yUBzSPFPAS"
      },
      "source": [
        "# 5. Train on you custom dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssw3M-5HFQ3a"
      },
      "outputs": [],
      "source": [
        "from detectron2.data.datasets import register_coco_instances\n",
        "register_coco_instances(\"my_dataset_train\", {}, training_set_annotations, training_set_images)\n",
        "register_coco_instances(\"my_dataset_val\", {}, validation_set_annotations, validation_set_images)\n",
        "\n",
        "train_metadata = MetadataCatalog.get(\"my_dataset_train\")\n",
        "train_dataset_dicts = DatasetCatalog.get(\"my_dataset_train\")\n",
        "\n",
        "val_metadata = MetadataCatalog.get(\"my_dataset_val\")\n",
        "val_dataset_dicts = DatasetCatalog.get(\"my_dataset_val\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualize some random samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "for d in random.sample(train_dataset_dicts, 1):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=train_metadata, scale=0.5)\n",
        "    vis = visualizer.draw_dataset_dict(d)\n",
        "    plt.imshow(vis.get_image()[:, :, ::-1])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gQNZNnWLpnc"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set your output directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_dir = \"path_to_output_directory\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.evaluation import COCOEvaluator\n",
        "from detectron2.data import build_detection_test_loader\n",
        "from detectron2.data import DatasetMapper\n",
        "from detectron2.LossEvalHook import LossEvalHook\n",
        "\n",
        "class MyTrainer(DefaultTrainer):\n",
        "    @classmethod\n",
        "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "        if output_folder is None:\n",
        "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
        "        return COCOEvaluator(dataset_name, cfg, True, output_folder)\n",
        "                     \n",
        "    def build_hooks(self):\n",
        "        hooks = super().build_hooks()\n",
        "        hooks.insert(-1,LossEvalHook(\n",
        "            cfg.TEST.EVAL_PERIOD,\n",
        "            self.model,\n",
        "            build_detection_test_loader(\n",
        "                self.cfg,\n",
        "                self.cfg.DATASETS.TEST[0],\n",
        "                DatasetMapper(self.cfg,True)\n",
        "            )\n",
        "        ))\n",
        "        return hooks\n",
        "    \n",
        "\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "import os\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.OUTPUT_DIR = output_dir\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
        "cfg.DATASETS.TEST = (\"my_dataset_val\",)\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.TEST.EVAL_PERIOD = 150\n",
        "\n",
        "## Increase input image size for better resolution\n",
        "#cfg.INPUT.MIN_SIZE_TRAIN = (640, 672, 704, 736, 768, 800)\n",
        "#cfg.INPUT.MAX_SIZE_TRAIN = 1333\n",
        "\n",
        "# Set model weights and move them to CPU\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "cfg.MODEL.DEVICE = \"cpu\"  # Set model to graphic device, CPU works for all but will be slower\n",
        "\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
        "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
        "cfg.SOLVER.MAX_ITER = 300    # 1500 default\n",
        "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
        "\n",
        "# Adjust anchor sizes and aspect ratios\n",
        "#cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[32, 64, 128, 256, 512]]\n",
        "#cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [[0.5, 1.0, 2.0]]\n",
        "\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   # Default is 512, using 256 for this dataset.\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # State number of classes, do not include bg\n",
        "# NOTE: this config means the number of classes, without the background. Do not use num_classes+1 here.\n",
        "\n",
        "# Increase the mask loss weight if segmentation is not accurate\n",
        "#cfg.MODEL.ROI_HEADS.MASK_LOSS_WEIGHT = 2.0\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# trainer = DefaultTrainer(cfg)\n",
        "trainer = MyTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Start the training process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.train() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save training results\n",
        "\n",
        "Change the yaml directory to your specific destination"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uI3zLAc3yeWq"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "# Save the configuration to a config.yaml file\n",
        "config_yaml_path = \"path_to_directory/config.yaml\" # adjust as needed\n",
        "with open(config_yaml_path, 'w') as file:\n",
        "    yaml.dump(cfg, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate the loss plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "experiment_folder = output_dir\n",
        "\n",
        "def load_json_arr(json_path):\n",
        "    lines = []\n",
        "    with open(json_path, 'r') as f:\n",
        "        for line in f:\n",
        "            lines.append(json.loads(line))\n",
        "    return lines\n",
        "\n",
        "experiment_metrics = load_json_arr(experiment_folder + 'metrics.json')\n",
        "\n",
        "# Creating a figure and axis with high resolution for publication\n",
        "plt.figure(figsize=(10, 6), dpi=300)\n",
        "\n",
        "# Improved plot for total_loss\n",
        "plt.plot(\n",
        "    [x['iteration'] for x in experiment_metrics if 'loss_mask' in x], \n",
        "    [x['total_loss'] for x in experiment_metrics if 'loss_mask' in x],\n",
        "    label='Training Loss', linewidth=1.5, marker='o', markersize=3, linestyle='-', color='blue'\n",
        ")\n",
        "\n",
        "# Improved plot for validation_loss\n",
        "plt.plot(\n",
        "    [x['iteration'] for x in experiment_metrics if 'validation_loss' in x], \n",
        "    [x['validation_loss'] for x in experiment_metrics if 'validation_loss' in x],\n",
        "    label='Validation Loss', linewidth=1.5, marker='s', markersize=3, linestyle='--', color='red'\n",
        ")\n",
        "\n",
        "# Enhancing the plot with grid, labels, title, and legend\n",
        "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "plt.xlabel('Iteration', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Loss', fontsize=14, fontweight='bold')\n",
        "plt.title('Training and Validation Loss over Iterations', fontsize=16, fontweight='bold')\n",
        "plt.legend(fontsize=12, loc='upper right')\n",
        "\n",
        "# Saving the figure with high quality\n",
        "plt.savefig(experiment_folder + 'loss_plot_high_quality.png', format='png', dpi=600)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6. Inference and evaluation using the trained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Remember to set model_final.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inference should use the config with parameters that are used in training\n",
        "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold\n",
        "predictor = DefaultPredictor(cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from detectron2.utils.visualizer import ColorMode, Visualizer\n",
        "import cv2\n",
        "import random\n",
        "from IPython.display import display, Image\n",
        "from io import BytesIO\n",
        "\n",
        "# Function to display an image in Jupyter Notebook\n",
        "def show_image(image):\n",
        "    \"\"\"Display the image in Jupyter notebook.\"\"\"\n",
        "    _, encoded_image = cv2.imencode('.png', image)\n",
        "    display(Image(data=encoded_image.tobytes()))\n",
        "\n",
        "# Assuming val_dataset_dicts and val_metadata are defined elsewhere\n",
        "for d in random.sample(val_dataset_dicts, 5):  # Select a number of images for display\n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=val_metadata,\n",
        "                   scale=0.8,\n",
        "                   instance_mode=ColorMode.IMAGE_BW)  # Remove the colors of unsegmented pixels\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    show_image(out.get_image()[:, :, ::-1])  # Display the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "evaluator = COCOEvaluator(\"my_dataset_val\", output_dir=output_dir)\n",
        "val_loader = build_detection_test_loader(cfg, \"my_dataset_val\")\n",
        "print(inference_on_dataset(predictor.model, val_loader, evaluator))\n",
        "# another equivalent way to evaluate the model is to use `trainer.test`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load a new image and segment it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from detectron2.utils.visualizer import Visualizer\n",
        "import cv2\n",
        "from IPython.display import display, Image\n",
        "from io import BytesIO\n",
        "\n",
        "# Function to display an image in Jupyter Notebook\n",
        "def show_image(image):\n",
        "    \"\"\"Display the image in Jupyter notebook.\"\"\"\n",
        "    _, encoded_image = cv2.imencode('.png', image)\n",
        "    display(Image(data=encoded_image.tobytes()))\n",
        "\n",
        "# Load an image\n",
        "new_im = cv2.imread(\"path_to_image\")\n",
        "outputs = predictor(new_im)\n",
        "\n",
        "# Use `Visualizer` to draw the predictions on the image.\n",
        "v = Visualizer(new_im[:, :, ::-1], metadata=train_metadata)\n",
        "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "\n",
        "# Display the image with predictions\n",
        "show_image(out.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Process multiple images in a directory and save the results in an output directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Directory path to the input images folder\n",
        "input_images_directory = \"path\"\n",
        "\n",
        "# Output directory where the segmented images will be saved\n",
        "output_directory = \"path\"  \n",
        "\n",
        "# Loop over the images in the input folder\n",
        "for image_filename in os.listdir(input_images_directory):\n",
        "    image_path = os.path.join(input_images_directory, image_filename)\n",
        "    new_im = cv2.imread(image_path)\n",
        "\n",
        "    # Perform prediction on the new image\n",
        "    outputs = predictor(new_im)  # Format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
        "\n",
        "    # We can use `Visualizer` to draw the predictions on the image.\n",
        "    v = Visualizer(new_im[:, :, ::-1], metadata=train_metadata)\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "\n",
        "    # Create the output filename with _result extension\n",
        "    result_filename = os.path.splitext(image_filename)[0] + \"_result.png\"\n",
        "    output_path = os.path.join(output_directory, result_filename)\n",
        "\n",
        "    # Save the segmented image\n",
        "    cv2.imwrite(output_path, out.get_image()[:, :, ::-1])\n",
        "\n",
        "print(\"Segmentation of all images completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Saving binary masks for each class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "\n",
        "# Directory path to the input images folder\n",
        "input_images_directory = \"path\"\n",
        "\n",
        "# Output directory where the segmented images will be saved\n",
        "output_directory = \"path\"  \n",
        "\n",
        "# Loop over the images in the input folder\n",
        "for image_filename in os.listdir(input_images_directory):\n",
        "    if not image_filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "        continue  # Skip non-image files\n",
        "\n",
        "    image_path = os.path.join(input_images_directory, image_filename)\n",
        "    new_im = cv2.imread(image_path)\n",
        "\n",
        "    if new_im is None:\n",
        "        print(f\"Failed to load image: {image_path}\")\n",
        "        continue\n",
        "\n",
        "    # Perform prediction on the new image\n",
        "    outputs = predictor(new_im)  # Format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
        "\n",
        "    # Check if predictions are available\n",
        "    if len(outputs[\"instances\"].pred_masks) == 0:\n",
        "        print(f\"No objects detected in image: {image_filename}\")\n",
        "        continue  # Skip to the next image if no objects are detected\n",
        "\n",
        "    # Create a dictionary to store the mask for each class with unique integer labels\n",
        "    class_masks = {class_name: torch.zeros_like(outputs[\"instances\"].pred_masks[0], dtype=torch.uint8, device=torch.device(\"cpu\"))\n",
        "                   for class_name in train_metadata.thing_classes}\n",
        "\n",
        "    # Assign a unique integer label to each object in the mask\n",
        "    for i, pred_class in enumerate(outputs[\"instances\"].pred_classes):\n",
        "        class_name = train_metadata.thing_classes[pred_class]\n",
        "        class_masks[class_name] = torch.where(outputs[\"instances\"].pred_masks[i].to(device=torch.device(\"cpu\")),\n",
        "                                              i + 1,\n",
        "                                              class_masks[class_name])\n",
        "\n",
        "    # Save the masks for each class with unique integer labels\n",
        "    for class_name, class_mask in class_masks.items():\n",
        "        # Convert the tensor to a NumPy array and then to a regular (CPU) array\n",
        "        class_mask_np = class_mask.cpu().numpy()\n",
        "\n",
        "        # Create the output filename with _class_name_result.png extension\n",
        "        class_filename = os.path.splitext(image_filename)[0] + f\"_{class_name}_result.png\"\n",
        "        class_output_path = os.path.join(output_directory, class_filename)\n",
        "\n",
        "        # Save the image with unique integer labels\n",
        "        cv2.imwrite(class_output_path, class_mask_np.astype(np.uint8))\n",
        "\n",
        "print(\"Segmentation of all images completed.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
